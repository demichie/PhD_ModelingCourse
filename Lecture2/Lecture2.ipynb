{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjsPU407FYeN3QvHRVLEie",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demichie/PhD_ModelingCourse/blob/main/Lecture2/Lecture2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gxoGbla3nw_"
      },
      "outputs": [],
      "source": [
        "# Imports globali che useremo frequentemente\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Impostazioni per i plot (opzionale, ma rende i plot più belli)\n",
        "plt.style.use('seaborn-v0_8-whitegrid') # o un altro stile che preferisci\n",
        "plt.rcParams['figure.figsize'] = (8, 5)\n",
        "plt.rcParams['font.size'] = 12"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 2: Principles of Numerical Modelling in Geosciences\n",
        "\n",
        "## Part 1: Recap and Continuation of Lecture 1\n",
        "\n",
        "In this first part, we will pick up where we left off in Lecture 1, discussing numerical solutions for ODEs, their implementation, and aspects of accuracy and stability.\n",
        "\n",
        "Topics covered:\n",
        "*   Numerical solution of Radioactive Decay (Euler's Method)\n",
        "*   Explicit vs. Implicit Euler\n",
        "*   Numerical Accuracy and Stability\n",
        "*   Summary of Lecture 1 (conceptual)\n",
        "\n",
        "![Radioactive Decay C14](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/decay_c14.png?raw=1)"
      ],
      "metadata": {
        "id": "uIkOiG-X35Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical Solution of Radioactive Decay (Explicit Euler)\n",
        "\n",
        "Recall the ODE for radioactive decay:\n",
        "$$ \\frac{dN}{dt} = -\\lambda N(t) $$\n",
        "\n",
        "Discretizing with the **Explicit Euler method**:\n",
        "We approximate the derivative as $\\frac{dN}{dt} \\approx \\frac{N^{n+1} - N^n}{\\Delta t}$ and evaluate the right-hand side at time $t^n$:\n",
        "$$ \\frac{N^{n+1} - N^n}{\\Delta t} = -\\lambda N^n $$\n",
        "Rearranging for $N^{n+1}$:\n",
        "$$ N^{n+1} = N^n - \\lambda \\Delta t N^n = N^n (1 - \\lambda \\Delta t) $$\n",
        "\n",
        "**Summary of Explicit Euler for Radioactive Decay:**\n",
        "*   Initial value: $N^0 = N_0$\n",
        "*   Update formula: $N^{n+1} = N^n (1 - \\lambda \\Delta t)$\n",
        "*   Iterate for $n = 0, 1, \\dots$"
      ],
      "metadata": {
        "id": "MErta_8H38Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python Implementation: Euler's Method for Radioactive Decay\n",
        "\n",
        "# Parameters\n",
        "lambda_ = 0.1  # Decay constant\n",
        "N0 = 100       # Initial quantity\n",
        "T_max_decay = 50   # Total simulation time\n",
        "dt_decay = 1.0     # Time step\n",
        "\n",
        "# Time array\n",
        "time_decay = np.arange(0, T_max_decay + dt_decay, dt_decay)\n",
        "\n",
        "# Numerical solution (Euler method)\n",
        "N_euler = np.zeros_like(time_decay)\n",
        "N_euler[0] = N0\n",
        "\n",
        "for n_step in range(len(time_decay) - 1):\n",
        "    N_euler[n_step + 1] = N_euler[n_step] * (1 - lambda_ * dt_decay)\n",
        "\n",
        "# Plotting the numerical solution\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(time_decay, N_euler, 'o--', label=f'Euler Approximation (dt={dt_decay})')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('N(t)')\n",
        "plt.title('Numerical Solution of Radioactive Decay (Explicit Euler)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8JB9UeGf3-zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Try a Larger Time Step (Explicit Euler)\n",
        "\n",
        "What happens if we increase the time step $\\Delta t$? Let's try $\\Delta t = 15.0$.\n",
        "The stability condition for explicit Euler for this problem is $\\Delta t \\le \\frac{1}{\\lambda}$.\n",
        "If $\\lambda = 0.1$, then $\\Delta t$ must be $\\le 10$. A $\\Delta t = 15.0$ should show instability."
      ],
      "metadata": {
        "id": "s7ua-QN14PyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters (lambda_ and N0 from previous cell)\n",
        "# T_max_decay from previous cell\n",
        "\n",
        "dt_large_decay = 15.0  # New, larger time step\n",
        "time_large_dt_decay = np.arange(0, T_max_decay + dt_large_decay, dt_large_decay)\n",
        "\n",
        "N_euler_large_dt = np.zeros_like(time_large_dt_decay)\n",
        "N_euler_large_dt[0] = N0\n",
        "\n",
        "for n_step in range(len(time_large_dt_decay) - 1):\n",
        "    N_euler_large_dt[n_step + 1] = N_euler_large_dt[n_step] * (1 - lambda_ * dt_large_decay)\n",
        "\n",
        "# Plotting\n",
        "plt.plot(time_large_dt_decay, N_euler_large_dt, 'o--')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('N(t)')\n",
        "plt.title(f'Euler Method with Larger Time Step (dt={dt_large_decay})')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BCE-W-s34WmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical Instability\n",
        "Observations:\n",
        "*   With $\\Delta t=1.0$, the solution was qualitatively correct.\n",
        "*   With $\\Delta t=15.0$ (given $\\lambda=0.1$), we observe unphysical oscillations and negative values because $1 - \\lambda \\Delta t = 1 - 0.1 \\cdot 15 = 1 - 1.5 = -0.5 < 0$.\n",
        "*   The update rule becomes unstable if $1 - \\lambda \\Delta t < 0 \\Rightarrow \\Delta t > \\frac{1}{\\lambda}$.\n",
        "\n",
        "This highlights the **conditional stability** of the explicit Euler method.\n",
        "\n",
        "### Interpreting the Explicit Euler Scheme\n",
        "The explicit Euler method assumes the decay rate is constant over the time step $\\Delta t$, equal to its value at the *beginning* of the interval $[t^n, t^{n+1}]$.\n",
        "$$ N^{n+1} = N^n - (\\lambda N^n) \\Delta t $$\n",
        "\n",
        "### An Alternative Assumption: Implicit (Backward) Euler\n",
        "What if we assume the rate is constant over $[t^n, t^{n+1}]$, but equal to its value at the *end* of the interval?\n",
        "$$ N^{n+1} = N^n - (\\lambda N^{n+1}) \\Delta t $$\n",
        "This is the **Backward (Implicit) Euler Method**. Rearranging for $N^{n+1}$:\n",
        "$$ N^{n+1} (1 + \\lambda \\Delta t) = N^n \\Rightarrow N^{n+1} = \\frac{N^n}{1 + \\lambda \\Delta t} $$\n",
        "This scheme is *unconditionally stable* for this problem."
      ],
      "metadata": {
        "id": "YdV-nXhq4aWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python Implementation: Implicit Euler for Radioactive Decay\n",
        "\n",
        "lambda_val_implicit = 0.1  # Decay constant (can be same as lambda_)\n",
        "dt_implicit_decay = 15.0      # Time step (can be large)\n",
        "T_implicit_decay = 60       # Total time\n",
        "N0_implicit = 100           # Initial quantity\n",
        "\n",
        "times_implicit = np.arange(0, T_implicit_decay + dt_implicit_decay, dt_implicit_decay)\n",
        "\n",
        "N_implicit = np.zeros_like(times_implicit)\n",
        "N_implicit[0] = N0_implicit\n",
        "\n",
        "for n_step in range(len(times_implicit) - 1):\n",
        "    N_implicit[n_step + 1] = N_implicit[n_step] / (1 + lambda_val_implicit * dt_implicit_decay)\n",
        "\n",
        "plt.plot(times_implicit, N_implicit, 'o-', label=f'Implicit Euler (dt={dt_implicit_decay})')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('N(t)')\n",
        "plt.title('Implicit Euler for Radioactive Decay')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mNwFbJ2W4dTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numerical Accuracy and Stability\n",
        "\n",
        "### Analytical vs. Numerical (Explicit Euler)\n",
        "Let's compare the numerical solution from Explicit Euler with the exact analytical solution $N(t) = N_0 e^{-\\lambda t}$."
      ],
      "metadata": {
        "id": "a5YI7K9g4i0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for accuracy comparison\n",
        "lambda_acc = 0.5\n",
        "N0_acc = 100\n",
        "t_max_acc = 10\n",
        "dt_acc = 0.5  # Try changing this: 0.1, 1.0, 1.9 (stable), 2.1 (unstable for lambda=0.5)\n",
        "\n",
        "t_values_acc = np.arange(0, t_max_acc + dt_acc, dt_acc)\n",
        "\n",
        "# Analytical solution\n",
        "N_analytical_acc = N0_acc * np.exp(-lambda_acc * t_values_acc)\n",
        "\n",
        "# Explicit Euler method\n",
        "N_explicit_acc = np.zeros_like(t_values_acc) # Use np.zeros_like for consistency\n",
        "N_explicit_acc[0] = N0_acc\n",
        "for n_step in range(len(t_values_acc) - 1): # Corrected loop to use n_step+1 for assignment\n",
        "    N_explicit_acc[n_step + 1] = N_explicit_acc[n_step] - lambda_acc * N_explicit_acc[n_step] * dt_acc\n",
        "\n",
        "# Plotting\n",
        "plt.plot(t_values_acc, N_analytical_acc, label='Analytical', lw=2)\n",
        "plt.plot(t_values_acc, N_explicit_acc, 'o--', label=f'Explicit Euler (dt={dt_acc})')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('N(t)')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title('Radioactive decay: Analytical vs Explicit Euler')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "At7alJuM4lCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definition of Error\n",
        "We compare the numerical solution $N_n^{(\\text{num})}$ with the exact (analytical) solution $N(t_n)$.\n",
        "\n",
        "**Pointwise (absolute) error at time $t_n$**:\n",
        "$$ \\varepsilon_n = |N_n^{(\\text{num})} - N(t_n)| $$\n",
        "(Often the non-absolute difference $N_n^{(\\text{num})} - N(t_n)$ is also called error, but absolute error is common for plotting magnitudes).\n",
        "\n",
        "The error generally depends on:\n",
        "*   the time step size $\\Delta t$\n",
        "*   the numerical method used\n",
        "*   the regularity (smoothness) of the true solution"
      ],
      "metadata": {
        "id": "dgdcOHZ-4qVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Absolute Error\n",
        "\n",
        "# Parameters (use from previous cell: lambda_acc, N0_acc, t_max_acc)\n",
        "# dt_error_plot = 1.0  # Can choose a different dt for this specific plot\n",
        "dt_error_plot = dt_acc # Or use the same dt as the accuracy plot above\n",
        "t_error = np.arange(0, t_max_acc + dt_error_plot, dt_error_plot)\n",
        "\n",
        "# Analytical solution\n",
        "N_exact_error = N0_acc * np.exp(-lambda_acc * t_error)\n",
        "\n",
        "# Explicit Euler method\n",
        "N_num_error = np.zeros_like(t_error)\n",
        "N_num_error[0] = N0_acc\n",
        "for n_step in range(1, len(t_error)):\n",
        "    N_num_error[n_step] = N_num_error[n_step-1] - lambda_acc * N_num_error[n_step-1] * dt_error_plot\n",
        "\n",
        "# Compute absolute error\n",
        "error_abs = np.abs(N_exact_error - N_num_error)\n",
        "\n",
        "# Plot\n",
        "plt.plot(t_error, error_abs, 'r-o', label=f'Absolute error (dt={dt_error_plot})')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Absolute Error')\n",
        "plt.title('Absolute Error: Analytical vs Numerical (Explicit Euler)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-t793hsb4tJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relative Error\n",
        "The **relative error** is:\n",
        "$$ \\epsilon_{\\text{rel}}(t) = \\frac{|N_{\\text{exact}}(t) - N_{\\text{num}}(t)|}{|N_{\\text{exact}}(t)|} \\quad (\\text{for } N_{\\text{exact}}(t) \\neq 0) $$\n",
        "Relative error is more informative when:\n",
        "*   The quantity of interest becomes very small.\n",
        "*   We want to assess the error proportionally to the expected value."
      ],
      "metadata": {
        "id": "BjR_nXbf4wNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Relative Error\n",
        "# (Using N_exact_error and N_num_error from the previous cell)\n",
        "\n",
        "# Compute relative error, avoiding division by zero\n",
        "# N_exact_error is exponential, so > 0 for finite t.\n",
        "# Add a small epsilon for safety if N_exact_error can be zero.\n",
        "epsilon_div = 1e-15\n",
        "rel_error = np.abs(N_exact_error - N_num_error) / (np.abs(N_exact_error) + epsilon_div)\n",
        "# A more robust way for general cases:\n",
        "# rel_error = np.zeros_like(N_exact_error)\n",
        "# non_zero_mask = np.abs(N_exact_error) > epsilon_div\n",
        "# rel_error[non_zero_mask] = np.abs(N_exact_error[non_zero_mask] - N_num_error[non_zero_mask]) / np.abs(N_exact_error[non_zero_mask])\n",
        "\n",
        "\n",
        "# Plot\n",
        "plt.plot(t_error, rel_error, 'b-s', label=f'Relative error (dt={dt_error_plot})')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Relative Error')\n",
        "plt.title('Relative Error: Analytical vs Numerical (Explicit Euler)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vF8C9yI44yff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical Accuracy\n",
        "Accuracy refers to how close the numerical solution is to the exact (analytical) solution.\n",
        "*   With explicit Euler, reducing $\\Delta t$ generally improves accuracy (up to a point where round-off errors might dominate).\n",
        "*   Accuracy is influenced by the method’s **order**: Euler’s method is *first-order accurate*.\n",
        "\n",
        "### Numerical Stability\n",
        "A numerical method is **stable** if errors do not grow uncontrollably.\n",
        "*   Explicit Euler for decay is conditionally stable ($\\Delta t \\le 1/\\lambda$).\n",
        "*   Instability can make the numerical solution completely unreliable.\n",
        "\n"
      ],
      "metadata": {
        "id": "KGSU2IIA41lQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Implicit vs Explicit for Nonlinear ODEs\n",
        "\n",
        "### Recap from Lecture 1\n",
        "*   **Explicit (Euler):** Future value depends only on known quantities. Simple, conditionally stable.\n",
        "*   **Implicit (Backward Euler):** Future value appears on both sides. More robust, can be unconditionally stable. For linear ODEs, implementation was straightforward.\n",
        "\n",
        "**A Natural Question:** Should we always use implicit schemes because they are more stable?\n",
        "Let's look at a **nonlinear ODE** where implementing an implicit scheme requires more effort.\n",
        "\n",
        "*(Comparison of explicit unstable vs implicit stable from decay example)*\n",
        "![Explicit Unstable](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/image4.png?raw=1)\n",
        "![Implicit Stable](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/image5.png?raw=1)"
      ],
      "metadata": {
        "id": "JpwrIZuO44I9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Water Infiltration into Soil\n",
        "A common process in Earth sciences is rainwater infiltration into unsaturated soil.\n",
        "*   Described by **Richards’ equation** (nonlinear PDE).\n",
        "*   We consider a simplified, lumped, time-dependent version.\n",
        "*   Model volumetric water content $\\theta(t)$ decreasing due to percolation.\n",
        "\n",
        "*Reference: Hillel, D. (1998). Environmental Soil Physics. Academic Press.*\n",
        "\n",
        "![Soil Diagram](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/soil.png?raw=1)\n",
        "\n",
        "*Water content $\\theta$ is a ratio, from 0 (dry) to porosity (saturated).*"
      ],
      "metadata": {
        "id": "6b4BDmIr5Abp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Simplified Model for Water Infiltration\n",
        "Assume water is lost due to gravity-driven flow, with conductivity $K(\\theta)$ depending on water content:\n",
        "$$ \\frac{d\\theta}{dt} = -K(\\theta) $$\n",
        "A common empirical expression for hydraulic conductivity:\n",
        "$$ K(\\theta) = K_s \\cdot \\theta^n $$\n",
        "where:\n",
        "*   $K_s$: saturated conductivity (e.g., $10^{-5}$ to $10^{-6}$ m/s)\n",
        "*   $n > 1$: nonlinearity parameter (e.g., $n = 3$ or $4$)"
      ],
      "metadata": {
        "id": "T3b0pIiQ6s9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicit Euler Scheme for Infiltration\n",
        "Discretize $\\frac{d\\theta}{dt} = -K_s \\theta^m$ using forward Euler:\n",
        "$$ \\theta^{k+1} = \\theta^k - \\Delta t \\cdot K_s \\cdot (\\theta^k)^n $$"
      ],
      "metadata": {
        "id": "rKXcXLJm6vIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explicit Euler for Nonlinear Infiltration\n",
        "\n",
        "# Parameters\n",
        "Ks_infil = 1e-4       # Saturated hydraulic conductivity\n",
        "m_exp_infil = 3       # Nonlinearity exponent (using 'm' from equation)\n",
        "dt_infil_exp = 1000    # Time step (s)\n",
        "Tmax_infil = 100000    # Total time\n",
        "theta0_infil = 0.4    # Initial water content\n",
        "\n",
        "# Time array\n",
        "t_infil_exp = np.arange(0., Tmax_infil + dt_infil_exp, dt_infil_exp)\n",
        "theta_exp = np.zeros_like(t_infil_exp)\n",
        "theta_exp[0] = theta0_infil\n",
        "\n",
        "# Time integration\n",
        "for k_idx in range(1, len(t_infil_exp)):\n",
        "    theta_exp[k_idx] = theta_exp[k_idx-1] - dt_infil_exp * Ks_infil * theta_exp[k_idx-1]**m_exp_infil\n",
        "\n",
        "# Plot\n",
        "plt.plot(t_infil_exp, theta_exp, label=f'Explicit Euler (dt={dt_infil_exp})')\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Water content θ\")\n",
        "plt.title(\"Explicit Euler: Nonlinear infiltration\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zi07dGmJ6y1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implicit Scheme (Backward Euler) for Infiltration\n",
        "The backward Euler scheme reads:\n",
        "$$ \\theta^{k+1} = \\theta^k - \\Delta t \\cdot K_s \\cdot (\\theta^{k+1})^n $$\n",
        "Let $X = \\theta^{k+1}$. We need to find $X$ such that:\n",
        "$$ X = \\theta^k - \\Delta t \\cdot K_s \\cdot X^n $$\n",
        "Rearranging, we want to find the root of $G(X)$:\n",
        "$$ G(X) = X + \\Delta t \\cdot K_s \\cdot X^n - \\theta^k = 0 $$\n",
        "This is a **nonlinear algebraic equation** for $X = \\theta^{k+1}$. We need a numerical root-finding method.\n",
        "\n",
        "### Root-Finding: The Bisection Method - Idea\n",
        "The **bisection method** finds a root of a continuous function $G(X)$.\n",
        "*   Start with an interval $[a, b]$ where $G(a)$ and $G(b)$ have opposite signs ($G(a) \\cdot G(b) < 0$).\n",
        "*   The *Intermediate Value Theorem* guarantees a root in $(a, b)$.\n",
        "*   Repeatedly halve the interval, keeping the subinterval with the sign change.\n",
        "\n",
        "![Bisection Method Diagram](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/BisectionMethod.png?raw=1)\n",
        "\n",
        "**Visual Steps:**\n",
        "1. Find $a, b$ so $G(a)G(b)<0$.\n",
        "2. Midpoint $c = (a+b)/2$.\n",
        "3. If $G(c) \\approx 0$, $c$ is root.\n",
        "4. If $G(a)G(c)<0$, root is in $[a,c]$.\n",
        "5. Else, root is in $[c,b]$.\n",
        "6. Repeat."
      ],
      "metadata": {
        "id": "MnyDvlwe9UF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Bisection Method - Algorithm\n",
        "Given $G(X)$, interval $[a_0, b_0]$ with $G(a_0)G(b_0) < 0$, tolerances $\\epsilon_X$ and $\\epsilon_F$:\n",
        "1.  **Initialize:** $a = a_0$, $b = b_0$.\n",
        "2.  **Iterate:**\n",
        "    1. Midpoint: $c = (a+b)/2$.\n",
        "    2. Evaluate $G(c)$.\n",
        "    3. **Check convergence:** If $|G(c)| < \\epsilon_F$ OR $(b-a)/2 < \\epsilon_X$, then $c$ is the root. Stop.\n",
        "    4. **Update interval:**\n",
        "        *   If $G(a) \\cdot G(c) < 0$, set $b=c$.\n",
        "        *   Else, set $a=c$.\n",
        "3.  If max iterations reached, report failure.\n",
        "\n",
        "### Why Python Functions for Root-Finding?\n",
        "The bisection algorithm evaluates $G(X)$ many times.\n",
        "*   Defining $G(X)$ as a Python **function** makes code cleaner, reusable, and understandable.\n",
        "*   Separates \"what function to solve\" from \"how to solve it\".\n",
        "\n",
        "**Defining a function in Python:**\n",
        "\n",
        "```python\n",
        "def function_name(parameter1, parameter2, ...):\n",
        "    \"\"\"Optional: Docstring explaining what the function does.\"\"\"\n",
        "    # Body of the function: calculations\n",
        "    result = parameter1 + parameter2 # Example\n",
        "    return result # Value returned by the function\n",
        "```    \n"
      ],
      "metadata": {
        "id": "_JCcFxgf9fS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_numbers(x, y):\n",
        "    \"\"\"This function returns the sum of x and y.\"\"\"\n",
        "    sum_val = x + y\n",
        "    return sum_val\n",
        "\n",
        "z = add_numbers(5, 3)  # z will be 8\n",
        "print(f\"Example of function call: add_numbers(5,3) = {z}\")"
      ],
      "metadata": {
        "id": "FeF6NTdd9h3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implicit Infiltration: Python Functions for Bisection\n",
        "For $G(X) = X + \\Delta t \\cdot K_s \\cdot X^n - \\theta^k = 0$.\n",
        "Let $X = \\theta^{k+1}$ and $\\theta_{prev} = \\theta^k$.\n",
        "\n",
        "**1. Function to Solve, $G(X)$:**"
      ],
      "metadata": {
        "id": "mZMkSf-i-I6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def G_infiltration(X_current, theta_prev, dt, Ks, n_exponent):\n",
        "    \"\"\"\n",
        "    Calculates G(X) = X + dt*Ks*X^m - theta_prev for root finding.\n",
        "    X_current:  The current guess for theta^{k+1}.\n",
        "    theta_prev: Water content from previous step, theta^k.\n",
        "    dt: Time step.\n",
        "    Ks: Saturated hydraulic conductivity.\n",
        "    m_exponent: Nonlinearity exponent.\n",
        "    \"\"\"\n",
        "    term_nonlinear = dt * Ks * (X_current ** n_exponent)\n",
        "    return X_current + term_nonlinear - theta_prev"
      ],
      "metadata": {
        "id": "HO6IpbXM-KJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bisection_solver(func_G, a, b, tol=1e-7, max_iter=100,\n",
        "                     args_for_G=()):\n",
        "    \"\"\"\n",
        "    Finds a root of func_G(x, *args_for_G) = 0 in [a,b] by bisection.\n",
        "    args_for_G: A tuple of additional fixed arguments for func_G.\n",
        "    \"\"\"\n",
        "    Ga = func_G(a, *args_for_G)\n",
        "    Gb = func_G(b, *args_for_G) # Calculate Gb as well\n",
        "\n",
        "    if Ga * Gb > 0: # Check if signs are NOT opposite (and neither is zero)\n",
        "        # Handle cases where a or b is already a root\n",
        "        if abs(Ga) < tol: return a\n",
        "        if abs(Gb) < tol: return b\n",
        "\n",
        "        raise ValueError(\"Bisection: G(a) and G(b) must have opposite signs for a robust start.\")\n",
        "\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        c = (a + b) / 2.0\n",
        "\n",
        "        # Check interval width first for convergence\n",
        "        if (b - a) / 2.0 < tol:\n",
        "            return c\n",
        "\n",
        "        Gc = func_G(c, *args_for_G)\n",
        "\n",
        "        # Check function value at c for convergence\n",
        "        if abs(Gc) < tol:\n",
        "            return c\n",
        "\n",
        "        if Ga * Gc < 0: # Root is in [a, c]\n",
        "            b = c\n",
        "            # Gb = Gc # Optional: update Gb if c becomes the new b\n",
        "        else: # Root is in [c, b]\n",
        "            a = c\n",
        "            Ga = Gc # Crucial: update Ga if c becomes the new a\n",
        "\n",
        "    # print(f\"Warning: Bisection did not converge within {max_iter} iterations.\")\n",
        "    return (a + b) / 2.0 # Return best estimate if max_iter reached"
      ],
      "metadata": {
        "id": "zEgvnPO--QU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implicit Euler with Bisection: Python Implementation\n",
        "\n",
        "**Algorithm Steps for each time step `i`:**\n",
        "1. We know $\\theta[i-1]$ (i.e., $\\theta^k$).\n",
        "2. We want to find $\\theta[i]$ (i.e., $\\theta^{k+1}$).\n",
        "3. Function to solve: $G(X) = X + \\Delta t K_s X^n - \\theta[i-1] = 0$.\n",
        "4. Interval for $X$: $[a,b]$. For physical reasons (water content $\\theta \\ge 0$ and decreases or stays constant if $K_s=0$), a good choice is $a=0$ and $b=\\theta[i-1]$.\n",
        "    * $G(0) = -\\theta[i-1] \\le 0$.\n",
        "    * $G(\\theta[i-1]) = \\theta[i-1] + \\Delta t K_s (\\theta[i-1])^n - \\theta[i-1] = \\Delta t K_s (\\theta[i-1])^n \\ge 0$.\n",
        "    * If $\\theta[i-1]>0$, signs are opposite (or $G(\\theta[i-1])=0$ if $K_s=0$ or $\\theta[i-1]=0$).\n",
        "5. Use `bisection_solver` to find $X = \\theta[i]$ such that $G(X) \\approx 0$."
      ],
      "metadata": {
        "id": "BR2ADKn2-WC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Simulation Parameters (can reuse Ks_infil, m_exp_infil, theta0_infil) ---\n",
        "dt_infil_imp = 2000       # Time step (s) - can be larger for implicit\n",
        "Tmax_infil_imp = 100000    # Total time\n",
        "tol_bisection_infil = 1e-7 # Tolerance for bisection\n",
        "\n",
        "# --- Time array and solution initialization ---\n",
        "t_infil_imp = np.arange(0., Tmax_infil_imp + dt_infil_imp, dt_infil_imp)\n",
        "theta_implicit_infil = np.zeros_like(t_infil_imp)\n",
        "theta_implicit_infil[0] = theta0_infil\n",
        "\n",
        "# --- Time integration (Implicit Euler with Bisection) ---\n",
        "for i_idx in range(1, len(t_infil_imp)):\n",
        "    theta_prev_step = theta_implicit_infil[i_idx-1]\n",
        "\n",
        "    if theta_prev_step < tol_bisection_infil: # Effectively zero\n",
        "        theta_implicit_infil[i_idx] = 0.0\n",
        "        continue\n",
        "\n",
        "    # Define arguments for G_infiltration for this step\n",
        "    # args_for_G expects (theta_prev, dt, Ks, m_exponent)\n",
        "    current_args = (theta_prev_step, dt_infil_imp, Ks_infil, m_exp_infil)\n",
        "\n",
        "    # Set interval for bisection: [a_bis, b_bis]\n",
        "    a_bis = 0.0\n",
        "    b_bis = theta_prev_step\n",
        "\n",
        "    # Robustness check for bisection interval before calling\n",
        "    val_G_a = G_infiltration(a_bis, *current_args)\n",
        "    val_G_b = G_infiltration(b_bis, *current_args)\n",
        "\n",
        "    if val_G_a * val_G_b > 0:\n",
        "        if abs(val_G_a) < tol_bisection_infil: # a_bis is already a root\n",
        "            theta_implicit_infil[i_idx] = a_bis\n",
        "        elif abs(val_G_b) < tol_bisection_infil: # b_bis is already a root\n",
        "            theta_implicit_infil[i_idx] = b_bis\n",
        "        else:\n",
        "            # This case should ideally not happen if theta_prev_step > 0\n",
        "            # due to the nature of G(X) for this problem.\n",
        "            # It might indicate theta_prev_step is extremely small or an issue.\n",
        "            print(f\"Warning: Bisection interval G(a)G(b) > 0 at t={t_infil_imp[i_idx]}, theta_prev={theta_prev_step}\")\n",
        "            print(f\"G(a)={val_G_a}, G(b)={val_G_b}. Using previous theta as fallback.\")\n",
        "            theta_implicit_infil[i_idx] = theta_prev_step # Fallback\n",
        "        continue # Move to next time step\n",
        "\n",
        "    try:\n",
        "        theta_implicit_infil[i_idx] = bisection_solver(G_infiltration,\n",
        "                                                     a_bis, b_bis,\n",
        "                                                     tol=tol_bisection_infil,\n",
        "                                                     args_for_G=current_args)\n",
        "    except (ValueError, RuntimeError) as e:\n",
        "        print(f\"Error during bisection at t={t_infil_imp[i_idx]}: {e}\")\n",
        "        print(\"Using previous theta as fallback.\")\n",
        "        theta_implicit_infil[i_idx] = theta_prev_step\n",
        "        # break # Optionally stop simulation\n",
        "\n",
        "# --- Plotting ---\n",
        "plt.plot(t_infil_exp, theta_exp, '--', label=f'Explicit Euler (dt={dt_infil_exp})') # Plot explicit too for comparison\n",
        "plt.plot(t_infil_imp, theta_implicit_infil, 'o-', label=f'Implicit Euler (Bisection, dt={dt_infil_imp})')\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Water content θ\")\n",
        "plt.title(\"Nonlinear infiltration: Explicit vs Implicit (Bisection)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1laKo45E-bOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Finite Difference Approximations\n",
        "\n",
        "### From Differential Equations to Approximating Derivatives\n",
        "We've seen that many Earth Science processes are described by **differential equations**:\n",
        "*   Radioactive Decay: $\\frac{dN}{dt} = -\\lambda N$\n",
        "*   Newton's Cooling: $\\frac{dT}{dt} = -k(T-T_a)$\n",
        "*   Water Infiltration: $\\frac{d\\theta}{dt} = -K_s \\theta^n$\n",
        "\n",
        "To solve these numerically, we need to **approximate derivatives** using discrete values.\n",
        "\n",
        "### Recalling Time Derivatives: Our First Finite Differences\n",
        "We already used finite differences for the **time derivative** $\\frac{dy}{dt}$:\n",
        "\n",
        "**Explicit (Forward) Euler for $\\frac{dy}{dt} = f(y,t)$:**\n",
        "$$ \\frac{y^{k+1} - y^k}{\\Delta t} \\approx f(y^k, t^k) $$\n",
        "$\\frac{y^{k+1} - y^k}{\\Delta t}$ is a *forward difference approximation* of $\\frac{dy}{dt}$ at $t^k$.\n",
        "\n",
        "**Implicit (Backward) Euler for $\\frac{dy}{dt} = f(y,t)$:**\n",
        "$$ \\frac{y^{k+1} - y^k}{\\Delta t} \\approx f(y^{k+1}, t^{k+1}) $$\n",
        "\n",
        "Now, we extend this to approximate derivatives with respect to **spatial variables** (e.g., $\\frac{\\partial q}{\\partial x}$)."
      ],
      "metadata": {
        "id": "tuuS5rij-tmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finite Difference Method (FDM): Introduction\n",
        "*   Introduced by Euler (18th century).\n",
        "*   Replaces partial derivatives with approximations using node values, leading to algebraic equations.\n",
        "*   Typically used on structured grids.\n",
        "*   Easy to implement.\n",
        "\n",
        "For a 1D grid with uniform spacing $\\Delta x$, points are $x_i$.\n",
        "![1D Grid](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/grid.png?raw=1)\n",
        "\n",
        "At each grid point $x_i$, we approximate $\\left( \\frac{\\partial q}{\\partial x} \\right)_{x_i} \\approx F(\\dots, q_{i-1}, q_{i}, q_{i+1}, \\dots)$.\n",
        "![Grid with q values](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/grid_copy.png?raw=1)\n",
        "\n",
        "The idea comes from the derivative definition:\n",
        "$$ \\left( \\frac{dq}{dx} \\right)_{x_i} = \\lim_{\\delta x \\to 0} \\frac{ q(x_i + \\delta x)- q(x_i)}{\\delta x} $$\n",
        "We replace $\\delta x$ with a finite $\\Delta x$."
      ],
      "metadata": {
        "id": "LBHZova8-xWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approximating the First Derivative\n",
        "We want to approximate the slope of $q(x)$ at $x_i$.\n",
        "![Slope illustration](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/slope1.png?raw=1)\n",
        "\n",
        "**Forward Difference Scheme:** Uses $q_i$ and $q_{i+1}$.\n",
        "$$ \\left( \\frac{dq}{dx} \\right)_{x_i} \\approx \\frac{ q_{i+1} - q_i }{\\Delta x} $$\n",
        "![Forward Difference](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/slope_fw.png?raw=1)\n",
        "\n",
        "**Backward Difference Scheme:** Uses $q_i$ and $q_{i-1}$.\n",
        "$$ \\left( \\frac{dq}{dx} \\right)_{x_i} \\approx \\frac{ q_{i} - q_{i-1} }{\\Delta x} $$\n",
        "![Backward Difference](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/slope_bw.png?raw=1)\n",
        "\n",
        "**Central Difference Scheme:** Uses $q_{i-1}$ and $q_{i+1}$.\n",
        "$$ \\left( \\frac{dq}{dx} \\right)_{x_i} \\approx \\frac{ q_{i+1} - q_{i-1} }{2\\Delta x} $$\n",
        "![Central Difference](https://github.com/demichie/PhD_ModelingCourse/blob/main/Lecture2/FIGURES/slope_cent.png?raw=1)"
      ],
      "metadata": {
        "id": "Sx24TLf7-0DG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy of Finite Difference Schemes\n",
        "\n",
        "**Accuracy and Truncation Error**\n",
        "The **truncation error** is the difference between the exact derivative and its finite difference approximation. It arises from truncating a Taylor series.\n",
        "$$ \\frac{q(x_{i+1})-q(x_{i})}{\\Delta x} = \\left( \\frac{dq}{dx} \\right)_{x_i} + \\text{Truncation Error} $$\n",
        "\n",
        "**Taylor Series Expansion**\n",
        "Around $x_i$:\n",
        "$$ q(x) = q(x_i) + (x-x_i)\\left( \\frac{dq}{dx} \\right)_{x_i} + \\frac{(x-x_i)^2}{2!}\\left( \\frac{d^2q}{dx^2} \\right)_{x_i} + \\frac{(x-x_i)^3}{3!}\\left( \\frac{d^3q}{dx^3} \\right)_{x_i} + O((x-x_i)^4) $$\n",
        "\n",
        "\n",
        "For $x = x_{i+1} = x_i + \\Delta x$:\n",
        "$$ q(x_{i+1}) = q_i + \\Delta x \\left( \\frac{dq}{dx} \\right)_{i} + \\frac{\\Delta x^2}{2}\\left( \\frac{d^2q}{dx^2} \\right)_{i} + \\frac{\\Delta x^3}{6}\\left( \\frac{d^3q}{dx^3} \\right)_{i} + O(\\Delta x^4) $$\n",
        "For $x = x_{i-1} = x_i - \\Delta x$:\n",
        "$$ q(x_{i-1}) = q_i - \\Delta x \\left( \\frac{dq}{dx} \\right)_{i} + \\frac{\\Delta x^2}{2}\\left( \\frac{d^2q}{dx^2} \\right)_{i} - \\frac{\\Delta x^3}{6}\\left( \\frac{d^3q}{dx^3} \\right)_{i} + O(\\Delta x^4) $$\n",
        "$O(\\Delta x^k)$ means \"terms of order $\\Delta x^k$ and higher.\""
      ],
      "metadata": {
        "id": "680juIa9-25G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Truncation Error: Forward Difference**\n",
        "From $q(x_{i+1})$ expansion:\n",
        "$$ \\frac{q_{i+1} - q_i}{\\Delta x} = \\left( \\frac{dq}{dx} \\right)_{x_i} + {\\frac{\\Delta x}{2} \\left( \\frac{d^2q}{dx^2} \\right)_{x_i}} + O(\\Delta x^2) $$\n",
        "The leading error term is $\\propto \\Delta x$. This is **first-order accurate**, $O(\\Delta x)$.\n",
        "\n",
        "**Truncation Error: Backward Difference**\n",
        "From $q(x_{i-1})$ expansion:\n",
        "$$ \\frac{q_i - q_{i-1}}{\\Delta x} = \\left( \\frac{dq}{dx} \\right)_{x_i} - {\\frac{\\Delta x}{2} \\left( \\frac{d^2q}{dx^2} \\right)_{x_i}} + O(\\Delta x^2) $$\n",
        "Also **first-order accurate**, $O(\\Delta x)$.\n",
        "\n",
        "**Truncation Error: Central Difference**\n",
        "Subtracting $q(x_{i-1})$ expansion from $q(x_{i+1})$ expansion:\n",
        "$$ q(x_{i+1}) - q(x_{i-1}) = 2 \\Delta x \\left( \\frac{dq}{dx} \\right)_{x_i} + \\frac{2\\Delta x^3}{6}\\left( \\frac{d^3q}{dx^3} \\right)_{x_i} + O(\\Delta x^5) $$\n",
        "So,\n",
        "$$ \\frac{q_{i+1} - q_{i-1}}{2\\Delta x} = \\left( \\frac{dq}{dx} \\right)_{x_i} + {\\frac{\\Delta x^2}{6}\\left( \\frac{d^3q}{dx^3} \\right)_{x_i}} + O(\\Delta x^4) $$\n",
        "The leading error term is $\\propto \\Delta x^2$. This is **second-order accurate**, $O(\\Delta x^2)$.\n",
        "\n",
        "**Summary & Remarks:**\n",
        "*   Truncation error measures local accuracy.\n",
        "*   Order of accuracy: power of $\\Delta x$ in the leading error term.\n",
        "*   Higher order uses more points or cancels more Taylor terms."
      ],
      "metadata": {
        "id": "yrJC1KcuDaEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finite Differences: Practical Examples and Order Verification\n",
        "\n",
        "Let's apply these schemes to $f(x) = x^2$ and $f(x) = \\sin(x)$.\n",
        "\n",
        "**Printing Formatted Output: F-Strings in Python**\n",
        "F-strings (Python 3.6+) embed expressions in strings using `f\"...\"` and `{expression}`."
      ],
      "metadata": {
        "id": "NZm6_bCwD4PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variable_name = \"World\"\n",
        "number = 42\n",
        "print(f\"Hello, {variable_name}! The number is {number}.\")"
      ],
      "metadata": {
        "id": "L3cvgu55D9aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dx = 0.1\n",
        "f_prime_forward = 1.9000\n",
        "error_forward = 0.1000\n",
        "print(f\"Forward Diff (dx={dx:.2f}): {f_prime_forward:.4f}, Error: {error_forward:.4e}\")"
      ],
      "metadata": {
        "id": "Q3LOIE3zEBsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1:** $f(x) = x^2$\n",
        "\n",
        "Analytical derivative: $f'(x) = 2x$. At $x_0 = 1.0$, $f'(1.0) = 2.0$.\n",
        "\n",
        "Let $\\Delta x = 0.1$."
      ],
      "metadata": {
        "id": "BZNBah8gEOzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: f(x) = x^2\n",
        "\n",
        "def func_x_squared(x):\n",
        "    return x**2\n",
        "\n",
        "def deriv_x_squared(x):\n",
        "    return 2*x\n",
        "\n",
        "# Point and step size\n",
        "x0_ex1 = 1.0\n",
        "dx_ex1 = 0.1\n",
        "\n",
        "# Exact derivative\n",
        "f_prime_exact_ex1 = deriv_x_squared(x0_ex1)\n",
        "print(f\"Exact derivative of x^2 at x={x0_ex1}: {f_prime_exact_ex1:.4f}\")\n",
        "\n",
        "# Function values\n",
        "f_x0_val = func_x_squared(x0_ex1)\n",
        "f_x0_plus_dx_val = func_x_squared(x0_ex1 + dx_ex1)\n",
        "f_x0_minus_dx_val = func_x_squared(x0_ex1 - dx_ex1)\n",
        "\n",
        "# Forward Difference\n",
        "f_prime_forward_ex1 = (f_x0_plus_dx_val - f_x0_val) / dx_ex1\n",
        "error_forward_ex1 = abs(f_prime_forward_ex1 - f_prime_exact_ex1)\n",
        "print(f\"Forward Diff (dx={dx_ex1:.2f}): {f_prime_forward_ex1:.4f}, Error: {error_forward_ex1:.4e}\")\n",
        "\n",
        "# Backward Difference\n",
        "f_prime_backward_ex1 = (f_x0_val - f_x0_minus_dx_val) / dx_ex1\n",
        "error_backward_ex1 = abs(f_prime_backward_ex1 - f_prime_exact_ex1)\n",
        "print(f\"Backward Diff (dx={dx_ex1:.2f}): {f_prime_backward_ex1:.4f}, Error: {error_backward_ex1:.4e}\")\n",
        "\n",
        "# Central Difference\n",
        "f_prime_central_ex1 = (f_x0_plus_dx_val - f_x0_minus_dx_val) / (2 * dx_ex1)\n",
        "error_central_ex1 = abs(f_prime_central_ex1 - f_prime_exact_ex1)\n",
        "print(f\"Central Diff (dx={dx_ex1:.2f}): {f_prime_central_ex1:.4f}, Error: {error_central_ex1:.4e}\")\n",
        "\n",
        "# Note: For f(x)=x^2, f'''(x) = 0, so the central difference error term is theoretically zero.\n",
        "# The printed error_central should be very close to machine precision (e.g., 0 or 1e-15)."
      ],
      "metadata": {
        "id": "7hGWt4AfER9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2:** $f(x)=\\sin(x)$\n",
        "\n",
        "Analytical derivative: $f'(x) = \\cos(x)$. At $x_0 = \\pi/4$, $f'(\\pi/4) = \\cos(\\pi/4) \\approx 0.7071$.\n",
        "\n",
        "Let $\\Delta x = 0.1$."
      ],
      "metadata": {
        "id": "y27p8MthEbm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: f(x) = sin(x)\n",
        "\n",
        "def func_sin(x):\n",
        "    return np.sin(x)\n",
        "\n",
        "def deriv_sin(x):\n",
        "    return np.cos(x)\n",
        "\n",
        "# Point and step size\n",
        "x0_sin_ex2 = np.pi / 4.0\n",
        "dx_sin_ex2 = 0.1\n",
        "\n",
        "# Exact derivative\n",
        "f_prime_exact_sin_ex2 = deriv_sin(x0_sin_ex2)\n",
        "print(f\"Exact derivative of sin(x) at x={x0_sin_ex2:.4f}: {f_prime_exact_sin_ex2:.4f}\")\n",
        "\n",
        "# Function values\n",
        "f_x0_sin_val = func_sin(x0_sin_ex2)\n",
        "f_x0_plus_dx_sin_val = func_sin(x0_sin_ex2 + dx_sin_ex2)\n",
        "f_x0_minus_dx_sin_val = func_sin(x0_sin_ex2 - dx_sin_ex2)\n",
        "\n",
        "# Forward Difference\n",
        "f_prime_forward_sin_ex2 = (f_x0_plus_dx_sin_val - f_x0_sin_val) / dx_sin_ex2\n",
        "error_forward_sin_ex2 = abs(f_prime_forward_sin_ex2 - f_prime_exact_sin_ex2)\n",
        "print(f\"Fwd Sin (dx={dx_sin_ex2:.2f}): {f_prime_forward_sin_ex2:.4f}, Error: {error_forward_sin_ex2:.4e}\")\n",
        "\n",
        "# Backward Difference\n",
        "f_prime_backward_sin_ex2 = (f_x0_sin_val - f_x0_minus_dx_sin_val) / dx_sin_ex2\n",
        "error_backward_sin_ex2 = abs(f_prime_backward_sin_ex2 - f_prime_exact_sin_ex2)\n",
        "print(f\"Bwd Sin (dx={dx_sin_ex2:.2f}): {f_prime_backward_sin_ex2:.4f}, Error: {error_backward_sin_ex2:.4e}\")\n",
        "\n",
        "# Central Difference\n",
        "f_prime_central_sin_ex2 = (f_x0_plus_dx_sin_val - f_x0_minus_dx_sin_val) / (2 * dx_sin_ex2)\n",
        "error_central_sin_ex2 = abs(f_prime_central_sin_ex2 - f_prime_exact_sin_ex2)\n",
        "print(f\"Ctrl Sin (dx={dx_sin_ex2:.2f}): {f_prime_central_sin_ex2:.4f}, Error: {error_central_sin_ex2:.4e}\")"
      ],
      "metadata": {
        "id": "kdVWJUerEex5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerically Verifying the Order of Accuracy\n",
        "Error $\\approx C \\cdot (\\Delta x)^p$. Taking logarithms:\n",
        "\n",
        "$$ \\log(\\text{Error}) \\approx \\log(C) + p \\cdot \\log(\\Delta x) $$\n",
        "\n",
        "This is $Y = A + pX$. So, a plot of $\\log(\\text{Error})$ vs $\\log(\\Delta x)$ (a **log-log plot**) should be a line with slope $p$.\n",
        "\n",
        "**Understanding Log-Log Plots:**\n",
        "*   Useful for power-law relationships and data spanning orders of magnitude.\n",
        "*   Slope indicates convergence rate:\n",
        "    *   Order $p=1$: Halving $\\Delta x$ halves error (slope 1 on log-log).\n",
        "    *   Order $p=2$: Halving $\\Delta x$ quarters error (slope 2 on log-log).\n",
        "*   Higher order $\\Rightarrow$ steeper slope $\\Rightarrow$ faster convergence.\n"
      ],
      "metadata": {
        "id": "9GeC3ZblEkGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Order Verification for sin(x)\n",
        "\n",
        "# (Assumes func_sin, deriv_sin, x0_sin_ex2, f_prime_exact_sin_ex2 are defined)\n",
        "x0_for_order = x0_sin_ex2 # Use the same x0 as before\n",
        "exact_deriv_for_order = f_prime_exact_sin_ex2\n",
        "\n",
        "# Range of dx values\n",
        "dx_values_order = np.logspace(-1, -5, 10) # From 10^-1 to 10^-5, 10 points\n",
        "\n",
        "errors_forward_order = []\n",
        "errors_backward_order = []\n",
        "errors_central_order = []\n",
        "\n",
        "for dx_val_order in dx_values_order:\n",
        "    f0_ord = func_sin(x0_for_order)\n",
        "    f_plus_ord = func_sin(x0_for_order + dx_val_order)\n",
        "    f_minus_ord = func_sin(x0_for_order - dx_val_order)\n",
        "\n",
        "    errors_forward_order.append(abs(((f_plus_ord - f0_ord) / dx_val_order) - exact_deriv_for_order))\n",
        "    errors_backward_order.append(abs(((f0_ord - f_minus_ord) / dx_val_order) - exact_deriv_for_order))\n",
        "    errors_central_order.append(abs(((f_plus_ord - f_minus_ord) / (2 * dx_val_order)) - exact_deriv_for_order))\n",
        "\n",
        "errors_forward_order = np.array(errors_forward_order)\n",
        "errors_backward_order = np.array(errors_backward_order)\n",
        "errors_central_order = np.array(errors_central_order)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(9, 7))\n",
        "plt.loglog(dx_values_order, errors_forward_order, 'o-', label='Forward')\n",
        "plt.loglog(dx_values_order, errors_backward_order, 's--', label='Backward')\n",
        "plt.loglog(dx_values_order, errors_central_order, '^-', label='Central')\n",
        "\n",
        "# Reference lines for slopes\n",
        "if len(dx_values_order) > 0:\n",
        "    # Order 1 reference (adjust C1 to align with first point of forward error)\n",
        "    C1 = errors_forward_order[0] / dx_values_order[0]\n",
        "    plt.loglog(dx_values_order, C1 * dx_values_order**1, 'k:', lw=1.5, label='Slope 1 Ref')\n",
        "\n",
        "    # Order 2 reference (adjust C2 to align with first point of central error)\n",
        "    C2 = errors_central_order[0] / (dx_values_order[0]**2)\n",
        "    plt.loglog(dx_values_order, C2 * dx_values_order**2, 'k--', lw=1.5, label='Slope 2 Ref')\n",
        "\n",
        "plt.xlabel('$\\Delta x$ (Step Size)')\n",
        "plt.ylabel('Absolute Error')\n",
        "plt.title('Log-Log Plot: Error vs. $\\Delta x$ for Approximating $f\\'(\\sin(x))$')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.6)\n",
        "# plt.gca().invert_xaxis() # Make dx decrease to the right if preferred\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EeFWWbRlEnjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpreting the Log-Log Plot:**\n",
        "*   **Linear Segments:** Data points for each method form roughly straight lines (for larger $\\Delta x$). Slopes indicate observed order.\n",
        "*   **Forward/Backward:** Slope close to 1.\n",
        "*   **Central:** Slope close to 2 (more accurate, faster convergence).\n",
        "*   **Round-off Error Domination:** For extremely small $\\Delta x$ (e.g., $10^{-8}$ or less), error might increase or become erratic due to finite machine precision (catastrophic cancellation). For $\\Delta x$ in $10^{-1}$ to $10^{-5}$, truncation error usually dominates.\n",
        "\n",
        "This numerical experiment confirms our theoretical understanding of scheme accuracy.\n"
      ],
      "metadata": {
        "id": "_H_odHWhE-qC"
      }
    }
  ]
}